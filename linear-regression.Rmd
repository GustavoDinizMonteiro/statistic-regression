---
title: "Usando Regressão Linear para Explicar a votação de Deputados"
author: "Gustavo Monteiro"
date: "October 3, 2018"
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
---

```{r warning=FALSE, echo=FALSE, message=FALSE}
library(dataPreparation)
library(gridExtra)
library(tidyverse)
library(GGally)
library(caret)
library(broom)
library(here)

theme_set(theme_gray())
```

> A base de dados que será usada nesse estudo consiste em dados sobre as votações que candidatos à Câmara Federal de Deputados receberam nos anos de 2006 e 2010 (fonte: http://www.tse.jus.br), além de informações sobre arreadação de campanha, partido, escolaridade, etc.. dos mesmos.

A seguir uma breve decrição sobre os campos disponiveis para cada registro na base de dados.
```{r}
## Loading data with correct data types.

eleicoes_data <- read_csv(
  here('./eleicoes_2006_e_2010.csv'), 
  local= locale("br"),
  col_types = cols(
    ano = col_integer(), # ano de referencia
    sequencial_candidato = col_character(), # id do candidato
    quantidade_doacoes = col_integer(),
    quantidade_doadores = col_integer(), # número de doadores diferentes
    total_receita = col_double(), # soma em R$ das doações
    media_receita = col_double(), # média das doações
    recursos_de_outros_candidatos.comites = col_double(), # quantia em R$ das doações provenientes de outros candidatos ou comite partidário
    recursos_de_pessoas_fisicas = col_double(), # quantia em R$ das doações provenientes de outros CPFs
    recursos_de_pessoas_juridicas = col_double(), # quantia em R$ das doações provenientes de outros CNPJ
    recursos_proprios = col_double(), # quantia em R$ das doações provenientes do próprio candidato
    `recursos_de_partido_politico` = col_double(), # quantia em R$ das doações provenientes do partido político do candidato
    quantidade_despesas = col_integer(),
    quantidade_fornecedores = col_integer(), # número de fornecedores/despesas diferentes
    total_despesa = col_double(), # soma em R$ das despesas de campanha
    media_despesa = col_double(), # média das despesas de campanha
    votos = col_integer(), #  variável alvo. Se refere ao número de votos na campanha de 2006 ou 2010
    .default = col_character()))
```

Uma breve amostra sobre os dados: 
```{r}
eleicoes_data %>% 
  glimpse()

sample_n(eleicoes_data %>%  select(ano, nome, uf, partido), 7)
```
Para uma melhor descrição dos tipos das colunas:
```{r}
sapply(eleicoes_data , class)
```
Agora separamos os conjuntos de dados das duas eleições.
```{r}
# separating data by year
data_2006 = eleicoes_data %>% 
  filter(ano == 2006)

data_2010 = eleicoes_data %>% 
  filter(ano == 2010)
```

Com os dados separados vamos uma exploração inicial de alguns pontos quanto aos dados
que estão sendo tema de discussão atualmente, como por exemplo, participação femininina, 
escolaridade e ocupação dos candidatos além da origem da verba de suas campanhas.

Primeiramente vamos falar da participação feminina, com os numeros gerais das eleições.
```{r}
eleicoes_data %>%
  group_by(sexo, ano) %>%
  summarize(n = n()) %>%
  ggplot(aes(reorder(sexo,n), n)) +
  geom_bar(stat = "identity") + 
  labs(x="Gender", 
       y="Absolute Count") +
  facet_grid(. ~ano)
```

E agora por cada um dos pricipais partidos também em esfera nacional.
```{r}
parties_with_more_candidates_2006 = data_2006 %>% 
  group_by(partido) %>% 
  summarise(num = n()) %>% 
  top_n(5, num)

data_2006 %>% 
  filter(partido %in%  parties_with_more_candidates_2006$partido) %>% 
  group_by(partido, sexo) %>%
  summarise(num = n()) %>% 
  ggplot(aes(reorder(sexo, num), num)) +
  geom_col(stat = "identity") +
  labs(x="Gender", 
       y="Absolute Count") +
  facet_grid(. ~partido)
```
Como podemos ver, tanto em números gerais quanto para todos os partidos apresentados


Agora falando sobre o grau de escolaridade dos candidatos, em numeros gerais da eleição.
```{r}
# escolaridade
schooling = data_2006 %>% 
  group_by(grau) %>% 
  summarise(num = n())

schooling %>% 
  ggplot(aes(x = reorder(grau, num), y = num)) +
  geom_col() +
    labs(x="Degree of schooling", 
       y="Absolute Count") +
  coord_flip()
```
Vemos que maioria dos candidatos estão em um nível de entre ensino médio completo e ensino superior completo, o que pode parecer até uma noticia animadora.

Agora vemos as mais comuns ocupações dos cadidatos.
```{r}
accupation = data_2006 %>%
  filter(ocupacao != "OUTROS") %>% 
  group_by(ocupacao) %>% 
  summarise(num = n()) %>% 
  top_n(10, num)

accupation %>% 
  ggplot(aes(x = reorder(ocupacao, num), y = num)) +
  geom_col() +
  labs(x="Occupation", 
       y="Absolute Count") +
  coord_flip()
```
Vemos que maioria dos cadidatos são advogados ou empresários, remetendo a uma dominancia das classes 
mais bem afortunadas da sociedade, além de uma grande participação de politicos que já se declaram 
estritamente politicos.

```{r}
parties_with_more_money_2006 = data_2006 %>% 
  group_by(partido) %>% 
  summarise(
    total = sum(total_receita), 
    self = sum(recursos_proprios) + sum(recursos_de_partido_politico),
    donations = sum(recursos_de_pessoas_fisicas) + sum(recursos_de_pessoas_juridicas),
    by_people = sum(recursos_de_pessoas_fisicas),
    by_companies = sum(recursos_de_pessoas_juridicas)) %>% 
  top_n(5, total)

p1 <- parties_with_more_money_2006 %>% 
  ggplot(aes(x = reorder(partido, total), y = total)) +
  geom_col() +
      labs(x="Party", 
       y="Amount") +
  labs(title = "Partidos com mais dinheiro") +
  coord_flip()

p2 <- parties_with_more_money_2006 %>% 
  ggplot(aes(x = reorder(partido, self), y = self)) +
  geom_col() +
        labs(x="Party", 
       y="Amount") +
  labs(title = "Os com mais dinheiro próprio") +
  coord_flip()

p3 <- parties_with_more_money_2006 %>% 
  ggplot(aes(x = reorder(partido, donations), y = donations)) +
  geom_col() +
        labs(x="Party", 
       y="Amount") +
  labs(title = "Os com mais dinheiro doado") +
  coord_flip()

p4 <- parties_with_more_money_2006 %>% 
  ggplot(aes(x = reorder(partido, by_people), y = by_people)) +
  geom_col() +
        labs(x="Party", 
       y="Amount") +
  labs(title = "Com mais dinheiro doado por pessoas") +
  coord_flip()

p5 <- parties_with_more_money_2006 %>% 
  ggplot(aes(x = reorder(partido, by_companies), y = by_companies)) +
  geom_col() +
        labs(x="Party", 
       y="Amount") +
  labs(title = "Os com mais dinheiro doado por empresas") +
  coord_flip()

grid.arrange(p1, p2, p3, p4, p5, nrow = 3)
```

Por ultimo vamos ter uma visualização da correlação entre as variáveis.
```{r}
data_2006 %>%
  select(-partido,
         -uf,-nome,
         -estado_civil,
         -ocupacao,-ano,
         -cargo,-grau,-sexo,
         -sequencial_candidato) %>%
  na.omit() %>%
  ggcorr(palette = "RdBu",
         color = "grey50",
         label = TRUE, hjust = 1,
         label_size = 3, size = 4,
         nbreaks = 5, layout.exp = 7) +
  ggtitle("Correlation plot for 2006 elections")

data_2010 %>%
  select(-partido,
         -uf,-nome,
         -estado_civil,
         -ocupacao,-ano,
         -cargo,-grau,-sexo,
         -sequencial_candidato) %>%
  na.omit() %>%
  ggcorr(palette = "RdBu",
         color = "grey50",
         label = TRUE, hjust = 1,
         label_size = 3, size = 4,
         nbreaks = 5, layout.exp = 7) +
  ggtitle("Correlation plot for 2010 elections")
```


Agora, apresentados os dados, vamos tabalhar em uma regressão linear para explicar o numero 
de votos que o candidato conseguiu, e atráves disso, responder a uma série de perguntas que 
serão apresentadas no decorrer desse estudo.

Como primeira pergunta proposta,

## Um modelo de regressão múltipla com todas as variáveis é plausível para explicar a variação em y (número de votos) em 2006? Mesma pergunta para 2010.

Para responder essa pergunta, passaremos não somente pela criação e simples avaliação de um modelo, mas também pela análise de residuas e validação, nesse caminho, algumas outras questões serão respondidas, serão destacadas para o leitor, para que não hajam dúvidas.

Primeiramente vamos transformar todas as variáveis qualitativas em fatores, e depois novamente separar
os dados em dois conjuntos, um para cada uma das eleições.
```{r}
eleicoes_data = eleicoes_data %>% 
  mutate(uf = as.factor(uf),
         nome = as.factor(nome),
         sexo = as.factor(sexo),
         grau = as.factor(grau),
         nome = as.factor(nome),
         cargo = as.factor(cargo),
         partido = as.factor(partido),
         ocupacao = as.factor(ocupacao),
         estado_civil = as.factor(estado_civil),
         sequencial_candidato = as.numeric(sequencial_candidato))

data_2006 = eleicoes_data %>%
   filter(ano == 2006)

data_2010 = eleicoes_data %>% 
  filter(ano == 2010)
```

Agora temos os conjuntos de dados com os seguintes datatypes em suas colunas
```{r}
data_2006 %>%
  glimpse()
```

Agora vamos criar o conjunto de treino, para iniciarmos a modelagem da função linear,
criando primeiramente uma semente para que o estudo possa ser reproduzido com os 
mesmo resultados.
```{r}
set.seed(1)      # for reproducible example

data_2006$id <- 1:nrow(data_2006)
```

E também um conjunto de testes e outro de validação, com o de treino com 60% dos dados,
os outros 40% serão usados para geração dos conjuntos de validação e testes.

```{r}
training_data_2006 = data_2006 %>% 
  sample_frac(.6)

encoding <- build_encoding(dataSet = training_data_2006,
                           cols = c("uf","sexo","grau",
                                    "partido","estado_civil"),
                           verbose = F)

training_data_2006 <- one_hot_encoder(dataSet = training_data_2006,
                           encoding = encoding,
                           drop = TRUE,
                           verbose = F)

remaining_2006 = anti_join(data_2006, training_data_2006, by = 'id')

testing_data_2006 = remaining_2006 %>% 
  sample_frac(.5)

testing_data_2006 <- one_hot_encoder(dataSet = testing_data_2006,
                           encoding = encoding,
                           drop = TRUE,
                           verbose = F)

validate_data_2006 = anti_join(remaining_2006, testing_data_2006, by = 'id')

validate_data_2006 <- one_hot_encoder(dataSet = validate_data_2006,
                           encoding = encoding,
                           drop = TRUE,
                           verbose = F)

rm(remaining_2006)
```

E agora criando um modelo com todas as variáveis.
```{r}
model_2006 = lm(votos ~ partido.PSDB + partido.PT + quantidade_doacoes + quantidade_doadores + total_receita + media_receita
                + recursos_de_outros_candidatos.comites + recursos_de_pessoas_fisicas + recursos_de_pessoas_juridicas
                + recursos_proprios + recursos_de_partido_politico + quantidade_despesas + quantidade_fornecedores
                + total_despesa +  media_despesa + sexo.MASCULINO + `grau.SUPERIOR COMPLETO` + sexo.FEMININO
                + `grau.ENSINO FUNDAMENTAL COMPLETO` + `grau.ENSINO FUNDAMENTAL INCOMPLETO` + `grau.ENSINO MÉDIO COMPLETO`
                + `grau.ENSINO MÉDIO INCOMPLETO` + `grau.LÊ E ESCREVE` + `grau.SUPERIOR INCOMPLETO` + partido.DEM
                + `partido.PC do B` + `partido.PDT` + partido.PHS + partido.PMDB + partido.PP + partido.PPS + partido.PR
                + partido.PSB + partido.PSL + partido.PSOL + partido.PTB + partido.PV + estado.civil.CASADO.A. + estado.civil.DIVORCIADO.A.
                + `estado.civil.SEPARADO.A. JUDICIALMENTE` + `estado.civil.SOLTEIRO.A.` + `estado.civil.VIÚVO.A.`,
                data = testing_data_2006)
```

Agora que temos o modelo pronto, famos fazeer uma pequena análise de suas significancia.
```{r}
glance(model_2006)
```
Nossa estatistica de R² mostra ser moderada, explicando cerca de 54% da variação dos dados, 
e tendo um diferença mínima para o R² ajustado, o que é muito pouco satisfatória, tendo em vista 
a quantidade de variáveis usadas, existe o risco de uma estar atrapalhando outra.

Agora fazemos o mesmo processo para os dados de 2010
```{r}
data_2010$id <- 1:nrow(data_2010)

training_data_2010 = data_2010 %>% 
  sample_frac(.6)

encoding <- build_encoding(dataSet = training_data_2010,
                           cols = c("uf","sexo","grau",
                                    "partido","estado_civil"),
                           verbose = F)

training_data_2010 <- one_hot_encoder(dataSet = training_data_2010,
                           encoding = encoding,
                           drop = TRUE,
                           verbose = F)

remaining_2010 = anti_join(data_2010, training_data_2010, by = 'id')

testing_data_2010 = remaining_2010 %>% 
  sample_frac(.5)

testing_data_2010 <- one_hot_encoder(dataSet = testing_data_2010,
                           encoding = encoding,
                           drop = TRUE,
                           verbose = F)

validate_data_2010 = anti_join(remaining_2010, testing_data_2010, by = 'id')

validate_data_2010 <- one_hot_encoder(dataSet = validate_data_2010,
                           encoding = encoding,
                           drop = TRUE,
                           verbose = F)

rm(remaining_2010)

model_2010 = lm(votos ~ partido.PSDB + partido.PT + quantidade_doacoes + quantidade_doadores + total_receita + media_receita
                + recursos_de_outros_candidatos.comites + recursos_de_pessoas_fisicas + recursos_de_pessoas_juridicas
                + recursos_proprios + recursos_de_partido_politico + quantidade_despesas + quantidade_fornecedores
                + total_despesa +  media_despesa + sexo.MASCULINO + `grau.SUPERIOR COMPLETO` + sexo.FEMININO
                + `grau.ENSINO FUNDAMENTAL COMPLETO` + `grau.ENSINO FUNDAMENTAL INCOMPLETO` + `grau.ENSINO MÉDIO COMPLETO`
                + `grau.ENSINO MÉDIO INCOMPLETO` + `grau.LÊ E ESCREVE` + `grau.SUPERIOR INCOMPLETO` + partido.DEM
                + `partido.PC do B` + `partido.PDT` + partido.PHS + partido.PMDB + partido.PP + partido.PPS + partido.PR
                + partido.PSB + partido.PSL + partido.PSOL + partido.PTB + partido.PV + estado.civil.CASADO.A. + estado.civil.DIVORCIADO.A.
                + `estado.civil.SEPARADO.A. JUDICIALMENTE` + `estado.civil.SOLTEIRO.A.` + `estado.civil.VIÚVO.A.`,
                data = testing_data_2010)

glance(model_2010)
```

Vemos que, para os dados de 2010, o modelo com todas as variáveis se torna um pouco mais representativo,
explicando cerca de 64% da mudança nos dados, e com um R² ajustado bem próximo disso, então acho que podemos considerar que o modelo com todas as variáveis não seria válido para esses dados.

Pórem, uma análise embasada somento no R² e R² ajustado pode estar nos levando a uma opinião muito inocente sobre o modelo,
então, a seguir, faremos uma série de outras análises em cima do modelo, para podermos ter uma opinião mais fortemente embasado sobre sua eficacia.

Então, vamos ter um breve visão para uma das nossas perguntas.

> Quais variáveis conseguem explicar melhor o número de votos? Compare essas variáveis entre os modelos. Mesma coisa para as variáveis menos explicativas.

Primeiro vamos ver quais variáveis tiveram um p-valor mais alto, ou seja,
os que se mostram menos confiáveis.
```{r}
# preditores com p valor alto
tidy(model_2006, 
     conf.int = TRUE, 
     conf.level = .97) %>%
  top_n(3, p.value) %>% 
  ggplot(aes(reorder(term, p.value), p.value)) +
  geom_point() +
  labs(x = "Variable",
       y = "Estimation (97% of confidence)")
```

E agora, no extremo contrário, as variáveis com p-valor mais baixo.
```{r}
# preditores com um p valor baixo
tidy(model_2006, 
     conf.int = TRUE, 
     conf.level = 0.97) %>%
  arrange(p.value) %>%
  slice(1:3) %>%
  ggplot(aes(reorder(term, p.value), p.value)) +
  geom_hline(yintercept = 0.05) +
  geom_point(size = 3.5) +
  labs(x = "Variable",
       y = "Estimated value (97% of confidence)")
```

E agora para os dados de 2010, primeiramente para p-valor alto

```{r}
tidy(model_2010, 
     conf.int = TRUE, 
     conf.level = .97) %>%
  top_n(3, p.value) %>% 
  ggplot(aes(reorder(term, p.value), p.value)) +
  geom_point() +
  labs(x = "Variable",
       y = "Estimation (97% of confidence)")
```

e agora, p-valor baixo
```{r}
tidy(model_2010, 
     conf.int = TRUE, 
     conf.level = 0.97) %>%
  arrange(p.value) %>%
  slice(1:3) %>%
  ggplot(aes(reorder(term, p.value), p.value)) +
  geom_hline(yintercept = 0.05) +
  geom_point(size = 3.5) +
  labs(x = "Variable",
       y = "Estimated value (97% of confidence)")
```
Nos gráficos acima, podemos perceber em linhas gerais que variáveis ligadas ao montante de dinheiro que
os partidos investem eu suas campanhas parecem mais seguramente relacionadas ao número de vostos adquiridos
em ambas as campanhas, com a excessão da presensa da variável partido-PR para 2010, e como variáveis suspeitas de não terem relação com o número de votos estão as relacionadas com qual o partido politico e escolaridade do cadidato, juntamente com seu estado civil, que se torna menos importante ainda, nas eleições de 2010.

# Análise de resíduos
```{r}
model_2006 %>%
  ggplot(aes(.fitted, .resid)) + 
  geom_point() +
  stat_smooth(method="loess") + 
  geom_hline(col="red",
             yintercept = 0,
             linetype="dashed") + 
  labs(y="Residuals",
       x="Fitted values",
       title="Residual vs Fitted Plot (2006)")
```

```{r}
model_2010 %>%
  ggplot(aes(.fitted, .resid)) + 
  geom_point() +
  stat_smooth(method="loess") + 
  geom_hline(col="red",
             yintercept = 0,
             linetype="dashed") + 
  labs(y="Residuals",
       x="Fitted values",
       title="Residual vs Fitted Plot (2010)")
```

Para ambos os conjuntos de dados, vemos que a distribuição dos pontos não é aleatoria
nem igualmente distribuida ao longo do eixo x, o que pode mostrar que o modelo pode não estar 
considerando relações não lineares, ou indicar que variáveis que seriam importantes ao modelo 
não foram incluidas.

```{r}
model_2006 %>%
  ggplot(aes(.fitted, 
             sqrt(abs(.stdresid)))) + 
  geom_point(na.rm=TRUE) + 
  stat_smooth(method="loess",
              na.rm = TRUE) +
  labs(title = "Scale-Location (2006)",
       x= "Fitted Value",
       y = expression(sqrt("|Standardized residuals|")))
```

```{r}
model_2010 %>%
  ggplot(aes(.fitted, 
             sqrt(abs(.stdresid)))) + 
  geom_point(na.rm=TRUE) + 
  stat_smooth(method="loess",
              na.rm = TRUE) +
  labs(title = "Scale-Location (2010)",
       x= "Fitted Value",
       y = expression(sqrt("|Standardized residuals|")))
```

Novamente, ambos o modelos não mostram homocedasticidade e mostrarem um certo padrão, pode não estar 
considerando variáveis que são as reais responsáveis pela votação de um candidato, ou o excesso
de variáveis que podem estar atrapalhando o modelo, além do erro irredutivel.

```{r}
model_2006 %>%
  ggplot(aes(.hat, .stdresid)) + 
  geom_point(aes(size=.cooksd), na.rm=TRUE) +
  stat_smooth(method="loess", na.rm=TRUE) +
  xlab("Leverage")+ylab("Standardized Residuals") + 
  ggtitle("Residual vs Leverage Plot (2006)") + 
  scale_size_continuous("Cook's Distance", range=c(1,5)) +    
  theme(legend.position="bottom")
```

```{r}
model_2010 %>%
  ggplot(aes(.hat, .stdresid)) + 
  geom_point(aes(size=.cooksd), na.rm=TRUE) +
  stat_smooth(method="loess", na.rm=TRUE) +
  xlab("Leverage") +
  ylab("Standardized Residuals") + 
  ggtitle("Residual vs Leverage Plot (2010)") + 
  scale_size_continuous("Cook's Distance", range=c(1,5)) +    
  theme(legend.position="bottom")
```

Para ambas as eleições vemos muitos valores com distancias de cook muito altas, o que mostra o o modelo é distoante com muitos dos valores, o que pode nos dizer que o modelo é bom, pois existem muitos dados que se mostram grandes influenciadores do modelo, mesmo quando a modelagem pode os ver como ouliers.

```{r}
predictions <- model_2006 %>% predict(validate_data_2006)

data.frame( R2 = R2(predictions, validate_data_2006$votos),
            RMSE = RMSE(predictions, validate_data_2006$votos),
            MAE = MAE(predictions, validate_data_2006$votos),
            ERR = RMSE(predictions, validate_data_2006$votos)/
                  mean(validate_data_2006$votos))

predictions <- model_2006 %>% predict(testing_data_2006)

data.frame( R2 = R2(predictions, testing_data_2006$votos),
            RMSE = RMSE(predictions, testing_data_2006$votos),
            MAE = MAE(predictions, testing_data_2006$votos),
            ERR = RMSE(predictions, testing_data_2006$votos)/
              mean(testing_data_2006$votos))
```


```{r}
predictions <- model_2010 %>% predict(validate_data_2010)

data.frame( R2 = R2(predictions, validate_data_2010$votos),
            RMSE = RMSE(predictions, validate_data_2010$votos),
            MAE = MAE(predictions, validate_data_2010$votos),
            ERR = RMSE(predictions, validate_data_2010$votos)/
              mean(validate_data_2010$votos))

predictions <- model_2010 %>% predict(testing_data_2010)

data.frame( R2 = R2(predictions, testing_data_2010$votos),
            RMSE = RMSE(predictions, testing_data_2010$votos),
            MAE = MAE(predictions, testing_data_2010$votos),
            ERR = RMSE(predictions, testing_data_2010$votos)/
              mean(testing_data_2010$votos))
```

Agora vamos construir um modelo apenas com as variáveis jugadas como importantes pela análise de correlação
e medição do p-valor.

>2006

```{r}
mod_2006 <- lm(votos ~ total_receita * total_despesa * recursos_de_pessoas_juridicas,
          data = training_data_2006)

glance(mod_2006)
```

E ver aplicado a ele os mesmos processos de análise de qualidade que aplicamos ao anterior

```{r}
mod_2006 %>%
  ggplot(aes(.fitted, .resid)) + 
  geom_point() +
  stat_smooth(method="loess") + 
  geom_hline(col="red",
             yintercept=0,
             linetype="dashed") + 
  labs(y="Residuals",
       x="Fitted values",
       title="Residual vs Fitted Plot (2006)")
```

Vemos que o novo modelo acomoda melhor a distribuição dos dados em tono do eixo x, mais ainda não de 
forma tão satisfatória, tendo mais pontos para um lado que para outro, e um lado mais espalhado que o outro,
isso pode indicar a falta de alguma variável importante no modelo.
```{r}
mod_2006 %>%
  ggplot(aes(.fitted, 
             sqrt(abs(.stdresid)))) + 
  geom_point(na.rm=TRUE) + 
  stat_smooth(method="loess",
              na.rm = TRUE) +
  labs(title = "Scale-Location (2006)",
       x= "Fitted Value",
       y = expression(sqrt("|Standardized residuals|")))
```

Novamente, o modelo mostra certa homocedasticidade mas tem também os problemas coma aleatoriedade, tendo em vista que os pontos não são distribuidos igualmente, algo que pode estar não só atrelado ao erro irredutivel, mas ainda sim, mostra uma melhora significativa se comparado ao modelo com todas as variáveis.


```{r}
mod_2006 %>%
  ggplot(aes(.hat, .stdresid)) + 
  geom_point(aes(size=.cooksd), na.rm=TRUE) +
  stat_smooth(method="loess", na.rm=TRUE) +
  xlab("Leverage") + 
  ylab("Standardized Residuals") + 
  ggtitle("Residual vs Leverage Plot (2006)") + 
  scale_size_continuous("Cook's Distance", range=c(1,5)) +    
  theme(legend.position="bottom")
```

Vemos também valores bem menores para distancia de cook e para bem menos pontos distoantes, o que pode nos dizer que o modelo se encontra em conformidade considerável com os dados.

```{r}
predictions <- mod_2006 %>% predict(validate_data_2006)

data.frame( R2 = R2(predictions, validate_data_2006$votos),
            RMSE = RMSE(predictions, validate_data_2006$votos),
            MAE = MAE(predictions, validate_data_2006$votos),
            ERR = RMSE(predictions, validate_data_2006$votos)/
              mean(validate_data_2006$votos))

predictions <- mod_2006 %>% predict(testing_data_2006)

data.frame( R2 = R2(predictions, testing_data_2006$votos),
            RMSE = RMSE(predictions, testing_data_2006$votos),
            MAE = MAE(predictions, testing_data_2006$votos),
            ERR = RMSE(predictions, testing_data_2006$votos)/
              mean(testing_data_2006$votos))
```

```{r}
mod_2010 <- lm(votos ~ total_receita * total_despesa * recursos_de_pessoas_juridicas,
          data = training_data_2010)

glance(mod_2010)
```

```{r}
mod_2010 %>%
  ggplot(aes(.fitted, .resid)) + 
  geom_point() +
  stat_smooth(method="loess") + 
  geom_hline(col="red",
             yintercept=0,
             linetype="dashed") + 
  labs(y="Residuals",
       x="Fitted values",
       title="Residual vs Fitted Plot (2010)")
```


```{r}
mod_2010 %>%
  ggplot(aes(.fitted, 
             sqrt(abs(.stdresid)))) + 
  geom_point(na.rm=TRUE) + 
  stat_smooth(method="loess",
              na.rm = TRUE) +
  labs(title = "Scale-Location (2006 elections)",
       x= "Fitted Value",
       y = expression(sqrt("|Standardized residuals|")))
```


```{r}
mod_2010 %>%
  ggplot(aes(.hat, .stdresid)) + 
  geom_point(aes(size=.cooksd), na.rm=TRUE) +
  stat_smooth(method="loess", na.rm=TRUE) +
  xlab("Leverage") + 
  ylab("Standardized Residuals") + 
  ggtitle("Residual vs Leverage Plot (2006)") + 
  scale_size_continuous("Cook's Distance", range=c(1,5)) +    
  theme(legend.position="bottom")
```

```{r}
predictions <- mod_2010 %>% predict(validate_data_2010)

data.frame( R2 = R2(predictions, validate_data_2010$votos),
            RMSE = RMSE(predictions, validate_data_2010$votos),
            MAE = MAE(predictions, validate_data_2010$votos),
            ERR = RMSE(predictions, validate_data_2010$votos)/
              mean(validate_data_2010$votos))

predictions <- mod_2010 %>% predict(testing_data_2010)

data.frame( R2 = R2(predictions, testing_data_2010$votos),
            RMSE = RMSE(predictions, testing_data_2010$votos),
            MAE = MAE(predictions, testing_data_2010$votos),
            ERR = RMSE(predictions, testing_data_2010$votos)/
              mean(testing_data_2010$votos))
```

