---
title: "Usando Regressão Linear para Explicar a votação de Deputados"
author: "Gustavo Monteiro"
date: "October 3, 2018"
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
---

```{r warning=FALSE, echo=FALSE, message=FALSE}
library(dataPreparation)
library(tidyverse)
library(GGally)
library(broom)
library(here)

theme_set(theme_gray())
```

A base de dados que será usada nesse estudo consiste em dados sobre as votações que candidatos à Câmara Federal de Deputados receberam nos anos de 2006 e 2010, além de informações sobre arreadação de campanha, partido, escolaridade, etc.. dos mesmos.

A seguir uma breve decrição sobre os campos disponiveis para cada registro na base de dados.
```{r}
## Loading data with correct data types.

eleicoes_data <- read_csv(
  here('./eleicoes_2006_e_2010.csv'), 
  local= locale("br"),
  col_types = cols(
    ano = col_integer(), # ano de referencia
    sequencial_candidato = col_character(), # id do candidato
    quantidade_doacoes = col_integer(),
    quantidade_doadores = col_integer(), # número de doadores diferentes
    total_receita = col_double(), # soma em R$ das doações
    media_receita = col_double(), # média das doações
    recursos_de_outros_candidatos.comites = col_double(), # quantia em R$ das doações provenientes de outros candidatos ou comite partidário
    recursos_de_pessoas_fisicas = col_double(), # quantia em R$ das doações provenientes de outros CPFs
    recursos_de_pessoas_juridicas = col_double(), # quantia em R$ das doações provenientes de outros CNPJ
    recursos_proprios = col_double(), # quantia em R$ das doações provenientes do próprio candidato
    `recursos_de_partido_politico` = col_double(), # quantia em R$ das doações provenientes do partido político do candidato
    quantidade_despesas = col_integer(),
    quantidade_fornecedores = col_integer(), # número de fornecedores/despesas diferentes
    total_despesa = col_double(), # soma em R$ das despesas de campanha
    media_despesa = col_double(), # média das despesas de campanha
    votos = col_integer(), #  variável alvo. Se refere ao número de votos na campanha de 2006 ou 2010
    .default = col_character()))
```

Uma breve amostra sobre os dados: 
```{r}
eleicoes_data %>% 
  glimpse()

sample_n(eleicoes_data %>%  select(ano, nome, uf, partido), 7)
```
Para uma melhor descrição dos tipos das colunas:
```{r}
sapply(eleicoes_data , class)
```
Agora separamos os conjuntos de dados das duas eleições.
```{r}
# separating data by year
data_2006 = eleicoes_data %>% 
  filter(ano == 2006)

data_2010 = eleicoes_data %>% 
  filter(ano == 2010)
```

Com os dados separados vamos uma exploração inicial de alguns pontos quanto aos dados
que estão sendo tema de discussão atualmente, como por exemplo, participação femininina, 
escolaridade e ocupação dos candidatos além da origem da verba de suas campanhas.

Primeiramente vamos falar da participação feminina, com os numeros gerais das eleições.
```{r}
eleicoes_data %>%
  group_by(sexo, ano) %>%
  summarize(n = n()) %>%
  ggplot(aes(reorder(sexo,n), n)) +
  geom_bar(stat = "identity") + 
  labs(x="Gender", 
       y="Absolute Count") +
  facet_grid(. ~ano)
```

E agora por cada um dos pricipais partidos também em esfera nacional.
```{r}
parties_with_more_candidates_2006 = data_2006 %>% 
  group_by(partido) %>% 
  summarise(num = n()) %>% 
  top_n(5, num)

data_2006 %>% 
  filter(partido %in%  parties_with_more_candidates_2006$partido) %>% 
  group_by(partido, sexo) %>%
  summarise(num = n()) %>% 
  ggplot(aes(reorder(sexo, num), num)) +
  geom_bar(stat = "identity") + 
  labs(x="Gender", 
       y="Absolute Count") +
  facet_grid(. ~partido)
```
Como podemos ver, tanto em números gerais quanto para todos os partidos apresentados


Agora falando sobre o grau de escolaridade dos candidatos, em numeros gerais da eleição.
```{r}
# escolaridade
schooling = data_2006 %>% 
  group_by(grau) %>% 
  summarise(num = n())

schooling %>% 
  ggplot(aes(x = reorder(grau, num), y = num)) +
  geom_col() +
  coord_flip()
```
Vemos que maioria dos candidatos estão em um nível de entre ensino médio completo e ensino superior completo, o que pode parecer até uma noticia animadora.

Agora vemos as mais comuns ocupações dos cadidatos.
```{r}
accupation = data_2006 %>%
  filter(ocupacao != "OUTROS") %>% 
  group_by(ocupacao) %>% 
  summarise(num = n()) %>% 
  top_n(10, num)

accupation %>% 
  ggplot(aes(x = reorder(ocupacao, num), y = num)) +
  geom_col() +
  coord_flip()
```
Vemos que maioria dos cadidatos são advogados ou empresários, remetendo a uma dominancia das classes 
mais bem afortunadas da sociedade, além de uma grande participação de politicos que já se declaram 
estritamente politicos.

```{r}
parties_with_more_money_2006 = data_2006 %>% 
  group_by(partido) %>% 
  summarise(
    total = sum(total_receita), 
    self = sum(recursos_proprios) + sum(recursos_de_partido_politico),
    donations = sum(recursos_de_pessoas_fisicas) + sum(recursos_de_pessoas_juridicas),
    by_people = sum(recursos_de_pessoas_fisicas),
    by_companies = sum(recursos_de_pessoas_juridicas)) %>% 
  top_n(5, total)

parties_with_more_money_2006 %>% 
  ggplot(aes(x = reorder(partido, total), y = total)) +
  geom_col() +
  coord_flip()

parties_with_more_money_2006 %>% 
  ggplot(aes(x = reorder(partido, self), y = self)) +
  geom_col() +
  coord_flip()

parties_with_more_money_2006 %>% 
  ggplot(aes(x = reorder(partido, donations), y = donations)) +
  geom_col() +
  coord_flip()

parties_with_more_money_2006 %>% 
  ggplot(aes(x = reorder(partido, by_people), y = by_people)) +
  geom_col() +
  coord_flip()

parties_with_more_money_2006 %>% 
  ggplot(aes(x = reorder(partido, by_companies), y = by_companies)) +
  geom_col() +
  coord_flip()
```

Por ultimo vamos ter uma visualização da correlação entre as variáveis.
```{r}
data_2006 %>%
  select(-partido,
         -uf,-nome,
         -estado_civil,
         -ocupacao,-ano,
         -cargo,-grau,-sexo,
         -sequencial_candidato) %>%
  na.omit() %>%
  ggcorr(palette = "RdBu",
         color = "grey50",
         label = TRUE, hjust = 1,
         label_size = 3, size = 4,
         nbreaks = 5, layout.exp = 7) +
  ggtitle("Correlation plot for 2006 elections")

data_2010 %>%
  select(-partido,
         -uf,-nome,
         -estado_civil,
         -ocupacao,-ano,
         -cargo,-grau,-sexo,
         -sequencial_candidato) %>%
  na.omit() %>%
  ggcorr(palette = "RdBu",
         color = "grey50",
         label = TRUE, hjust = 1,
         label_size = 3, size = 4,
         nbreaks = 5, layout.exp = 7) +
  ggtitle("Correlation plot for 2006 elections")
```


Agora, apresentados os dados, vamos tabalhar em uma regressão linear para explicar o numero 
de votos que o candidato conseguiu, e atráves disso, responder a uma série de perguntas que 
serão apresentadas no decorrer desse estudo.

Como primeira pergunta proposta,
## Um modelo de regressão múltipla com todas as variáveis é plausível para explicar a variação em y (número de votos) em 2006? Mesma pergunta para 2010.

Primeiramente vamos transformar todas as variáveis qualitativas em fatores, e depois novamente separar
os dados em dois conjuntos, um para cada uma das eleições.
```{r}
eleicoes_data = eleicoes_data %>% 
  mutate(uf = as.factor(uf),
         nome = as.factor(nome),
         sexo = as.factor(sexo),
         grau = as.factor(grau),
         nome = as.factor(nome),
         cargo = as.factor(cargo),
         partido = as.factor(partido),
         ocupacao = as.factor(ocupacao),
         estado_civil = as.factor(estado_civil),
         sequencial_candidato = as.numeric(sequencial_candidato))

data_2006 = eleicoes_data %>%
   filter(ano == 2006)

data_2010 = eleicoes_data %>% 
  filter(ano == 2010)
```

Agora temos os conjuntos de dados com os seguintes datatypes em suas colunas
```{r}
data_2006 %>%
  glimpse()
```

Agora vamos criar o conjunto de treino, para iniciarmos a modelagem da função linear,
criando primeiramente uma semente para que o estudo possa ser reproduzido com os 
mesmo resultados.
```{r}
set.seed(1)      # for reproducible example

data_2006$id <- 1:nrow(data_2006)
```

E agora gerando o conjunto de testes, com 60% dos dados, os outros 40% serão usados 
para geração dos conjuntos de validação e testes.

```{r}
training_data_2006 = data_2006 %>% 
  sample_frac(.6)

encoding <- build_encoding(dataSet = training_data_2006,
                           cols = c("uf","sexo","grau",
                                    "partido","estado_civil"),
                           verbose = F)

training_data_2006 <- one_hot_encoder(dataSet = training_data_2006,
                           encoding = encoding,
                           drop = TRUE,
                           verbose = F)

remaining_2006 = anti_join(data_2006, training_data_2006, by = 'id')

testing_data_2006 = remaining_2006 %>% 
  sample_frac(.5)

testing_data_2006 <- one_hot_encoder(dataSet = testing_data_2006,
                           encoding = encoding,
                           drop = TRUE,
                           verbose = F)

validate_data_2006 = anti_join(remaining_2006, testing_data_2006, by = 'id')

validate_data_2006 <- one_hot_encoder(dataSet = validate_data_2006,
                           encoding = encoding,
                           drop = TRUE,
                           verbose = F)

rm(remaining_2006)
```

E agora criando um modelo com todas as variáveis.
```{r}
model_2006 = lm(votos ~ partido.PSDB + partido.PT + quantidade_doacoes + quantidade_doadores + total_receita + media_receita
                + recursos_de_outros_candidatos.comites + recursos_de_pessoas_fisicas + recursos_de_pessoas_juridicas
                + recursos_proprios + recursos_de_partido_politico + quantidade_despesas + quantidade_fornecedores
                + total_despesa +  media_despesa + sexo.MASCULINO + `grau.SUPERIOR COMPLETO` + sexo.FEMININO,
                data = testing_data_2006)
```

Agora que temos o modelo pronto, famos fazeer uma pequena análise de suas significancia.
```{r}
glance(model_2006)
```
Nossa estatistica de R² mostra ser moderada, explicando cerca de 53% da variação dos dados, 
e tendo um diferença mínima para o R² ajustado, o que é muito pouco satisfatória, tendo em vista 
a quantidade de variáveis usadas, existe o risco de uma estar atrapalhando outra.

Agora para os dados de 2010
```{r}
data_2010$id <- 1:nrow(data_2010)

training_data_2010 = data_2010 %>% 
  sample_frac(.6)

encoding <- build_encoding(dataSet = training_data_2010,
                           cols = c("uf","sexo","grau",
                                    "partido","estado_civil"),
                           verbose = F)

training_data_2010 <- one_hot_encoder(dataSet = training_data_2010,
                           encoding = encoding,
                           drop = TRUE,
                           verbose = F)

remaining_2010 = anti_join(data_2010, training_data_2010, by = 'id')

testing_data_2010 = remaining_2010 %>% 
  sample_frac(.5)

testing_data_2010 <- one_hot_encoder(dataSet = testing_data_2010,
                           encoding = encoding,
                           drop = TRUE,
                           verbose = F)

validate_data_2010 = anti_join(remaining_2010, testing_data_2010, by = 'id')

validate_data_2010 <- one_hot_encoder(dataSet = validate_data_2010,
                           encoding = encoding,
                           drop = TRUE,
                           verbose = F)

rm(remaining_2010)

model_2010 = lm(votos ~ partido.PSDB + partido.PT + quantidade_doacoes + quantidade_doadores + total_receita + media_receita
                + recursos_de_outros_candidatos.comites + recursos_de_pessoas_fisicas + recursos_de_pessoas_juridicas
                + recursos_proprios + recursos_de_partido_politico + quantidade_despesas + quantidade_fornecedores
                + total_despesa +  media_despesa + sexo.MASCULINO + `grau.SUPERIOR COMPLETO` + sexo.FEMININO,
                data = testing_data_2010)

glance(model_2010)
```

Vemos que, para os dados de 2010, o modelo com todas as variáveis se torna um pouco mais representativo,
explicando cerca de 63% da mudança nos dados, e com um R² ajustado bem próximo disso, então acho que podemos considerar que o modelo com todas as variáveis não seria válido para esses dados.
